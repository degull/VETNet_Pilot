# # <-- U-Net κµ¬μ΅° (λΈμ²΄)
# G:\VETNet_pilot\models\vetnet_backbone.py
# G:\VETNet_pilot\models\vetnet_backbone.py (μμ • λ²„μ „)
import torch
import torch.nn as nn
import torch.nn.functional as F

# ====================================================================
# [μμ΅΄μ„± 1] film_volterra_block.py μ—μ„ μ„ν¬νΈλλ” FiLM_VolterraBlock μ¤ν…
# (FiLM μ—°μ‚°μ΄ μ‹¤μ λ΅ μΌμ–΄λ‚λ„λ΅ μμ •)
# ====================================================================
class FiLM_VolterraBlock(nn.Module):
    """ ν…μ¤νΈλ¥Ό μ„ν• FiLM_VolterraBlock μ¤ν… """
    def __init__(self, dim, num_heads, ffn_expansion_factor=2.66, bias=False, volterra_rank=4):
        super().__init__()
        self.conv = nn.Conv2d(dim, dim, 1) 
    
    def forward(self, x, gamma=None, beta=None):
        # π’΅ μμ •λ λ¶€λ¶„: FiLM λ³€μ΅°κ°€ Feature Mapμ— μ§μ ‘ μ μ©λλ„λ΅ ν•¨
        if gamma is not None and beta is not None:
             x_mod = x * gamma + beta # FiLM μ—°μ‚° μ μ©
        else:
             x_mod = x
             
        # Residual Connection
        return x + self.conv(x_mod) 

# ====================================================================
# [μμ΅΄μ„± 2] Restormer κΈ°λ³Έ μ»΄ν¬λ„νΈ (μ μ§€)
# ... Downsample, Upsample ν΄λμ¤ μ μ§€ ...
# ====================================================================

class Downsample(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.body = nn.Conv2d(in_channels, in_channels * 2, kernel_size=3, stride=2, padding=1)
    def forward(self, x):
        return self.body(x)

class Upsample(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.body = nn.Sequential(
            nn.Conv2d(in_channels, out_channels * 4, kernel_size=1), 
            nn.PixelShuffle(2)
        )
    def forward(self, x):
        return self.body(x)

# ====================================================================
# Core Component: Encoder / Decoder (FiLM λΈ”λ΅ μ‹ν€€μ¤) (μ μ§€)
# ... Encoder, Decoder ν΄λμ¤ μ μ§€ ...
# ====================================================================

class Encoder(nn.Module):
    """
    FiLM_VolterraBlockμΌλ΅ κµ¬μ„±λ μΈμ½”λ” μ‹ν€€μ¤. 
    forward μ‹ gamma, betaλ¥Ό ν•„μλ΅ λ°›μµλ‹λ‹¤.
    """
    def __init__(self, dim, depth, **kwargs):
        super().__init__()
        self.blocks = nn.ModuleList([
            FiLM_VolterraBlock(dim, **kwargs) for _ in range(depth)
        ])

    def forward(self, x, gamma, beta): 
        for block in self.blocks:
            x = block(x, gamma, beta)
        return x

class Decoder(nn.Module):
    """
    FiLM_VolterraBlockμΌλ΅ κµ¬μ„±λ λ””μ½”λ” μ‹ν€€μ¤. 
    λ‚΄λ¶€μ μΌλ΅ μ¤‘λ¦½ FiLM νλΌλ―Έν„°(1, 0)λ¥Ό μƒμ„±ν•μ—¬ λΈ”λ΅μ— μ „λ‹¬ν•©λ‹λ‹¤.
    """
    def __init__(self, dim, depth, **kwargs):
        super().__init__()
        self.blocks = nn.ModuleList([
            FiLM_VolterraBlock(dim, **kwargs) for _ in range(depth)
        ])

    def forward(self, x):
        B, C, H, W = x.shape
        gamma = torch.ones_like(x[:, 0:1, :, :]).repeat(1, C, 1, 1)
        beta = torch.zeros_like(x[:, 0:1, :, :]).repeat(1, C, 1, 1)

        for block in self.blocks:
            x = block(x, gamma, beta)
        return x


# ====================================================================
# VETNet-Pilot Backbone: Restormer-Volterra (U-Net) (μ μ§€)
# ... RestormerVolterra ν΄λμ¤ μ μ§€ ...
# ====================================================================

class RestormerVolterra(nn.Module):
    """
    VETNet-Pilotμ λ©”μΈ λ³µμ› λ„¤νΈμ›ν¬ (Restormer κΈ°λ° U-Net κµ¬μ΅°)
    """
    def __init__(self, in_channels=3, out_channels=3, dim=48, 
                 num_blocks=[4,6,6,8], heads=[1,2,4,8], **kwargs):
        super().__init__()
        
        self.dim = dim

        self.patch_embed = nn.Conv2d(in_channels, dim, kernel_size=3, padding=1)
        
        # ----------------- Encoder -----------------
        self.encoder1 = Encoder(dim, num_blocks[0], num_heads=heads[0], **kwargs)
        self.down1 = Downsample(dim)
        
        self.encoder2 = Encoder(dim*2, num_blocks[1], num_heads=heads[1], **kwargs)
        self.down2 = Downsample(dim*2)
        
        self.encoder3 = Encoder(dim*4, num_blocks[2], num_heads=heads[2], **kwargs)
        self.down3 = Downsample(dim*4)

        # ----------------- Latent/Bottleneck -----------------
        self.latent = Encoder(dim*8, num_blocks[3], num_heads=heads[3], **kwargs)

        # ----------------- Decoder -----------------
        self.up3 = Upsample(dim*8, dim*4) 
        self.decoder3 = Decoder(dim*4, num_blocks[2], num_heads=heads[2], **kwargs)
        
        self.up2 = Upsample(dim*4, dim*2) 
        self.decoder2 = Decoder(dim*2, num_blocks[1], num_heads=heads[1], **kwargs)

        self.up1 = Upsample(dim*2, dim) 
        self.decoder1 = Decoder(dim, num_blocks[0], num_heads=heads[0], **kwargs)
        
        # ----------------- Refinement & Output -----------------
        self.refinement = Encoder(dim, num_blocks[0], num_heads=heads[0], **kwargs) 

        self.output = nn.Conv2d(dim, out_channels, kernel_size=3, padding=1)

    def _pad_and_add(self, up_tensor, skip_tensor):
        if up_tensor.shape[-2:] != skip_tensor.shape[-2:]:
            up_tensor = F.interpolate(up_tensor, size=skip_tensor.shape[-2:], mode='bilinear', align_corners=False)
        return up_tensor + skip_tensor

    def forward(self, x, film_params):
        (gamma1, beta1), (gamma2, beta2), (gamma3, beta3), (gamma4, beta4) = film_params
        
        x_embed = self.patch_embed(x) 

        # 2. Encoder Path (FiLM μ μ–΄ μ μ©)
        x2 = self.encoder1(x_embed, gamma1, beta1) 
        x3 = self.encoder2(self.down1(x2), gamma2, beta2) 
        x4 = self.encoder3(self.down2(x3), gamma3, beta3) 
        
        # 3. Latent/Bottleneck (FiLM μ μ–΄ μ μ©)
        x5 = self.latent(self.down3(x4), gamma4, beta4) 

        # 4. Decoder Path (Decoder.forwardμ—μ„ μ¤‘λ¦½ νλΌλ―Έν„° μλ™ μ²λ¦¬)
        x6 = self.decoder3(self._pad_and_add(self.up3(x5), x4)) 
        x7 = self.decoder2(self._pad_and_add(self.up2(x6), x3)) 
        x8 = self.decoder1(self._pad_and_add(self.up1(x7), x2)) 
        
        # 5. Refinement (Encoder ν΄λμ¤ μ‚¬μ©. μ¤‘λ¦½ νλΌλ―Έν„°λ¥Ό λ…μ‹μ μΌλ΅ μƒμ„± λ° μ „λ‹¬)
        neutral_gamma_refine = torch.ones_like(x_embed[:, 0:self.dim, :, :])
        neutral_beta_refine = torch.zeros_like(x_embed[:, 0:self.dim, :, :])
        
        x9 = self.refinement(x8, neutral_gamma_refine, neutral_beta_refine)

        # 6. Output (Residual Learning μ μ©)
        out = self.output(x9 + x_embed)
        return out


# ====================================================================
# μ½”λ“ κ²€μ¦ λ° ν…μ¤νΈ (μ μ§€)
# ... create_dummy_film_params ν•¨μ λ° if __name__ == '__main__': λΈ”λ΅ μ μ§€ ...
# ====================================================================

def create_dummy_film_params(dim):
    dims = [dim, dim * 2, dim * 4, dim * 8]
    params = []
    
    for i, c in enumerate(dims):
        gamma = torch.ones(1, c, 1, 1) 
        beta = torch.zeros(1, c, 1, 1)
        
        gamma[0, :min(10, c), 0, 0] = 1.0 + 0.1 * (i + 1)
        beta[0, :min(10, c), 0, 0] = 0.05 * (i + 1)
        
        params.append((gamma, beta))
    return params

if __name__ == '__main__':
    print("--- 3λ‹¨κ³„: vetnet_backbone.py μ½”λ“ κ²€μ¦ μ‹μ‘ ---")
    
    in_channels = 3
    out_channels = 3
    base_dim = 48 
    input_height = 256
    input_width = 384
    
    dummy_image = torch.randn(1, in_channels, input_height, input_width)
    print(f"1. μ…λ ¥ μ΄λ―Έμ§€ ν•νƒ (x): {dummy_image.shape}")

    dummy_film_params = create_dummy_film_params(base_dim)
    print(f"2. FiLM νλΌλ―Έν„° μ…‹ μƒμ„± μ™„λ£. (4μ)")
    print(f"   -> E1 νλΌλ―Έν„° μ±„λ„ ν¬κΈ°: {dummy_film_params[0][0].shape[1]}") 
    print(f"   -> E4 νλΌλ―Έν„° μ±„λ„ ν¬κΈ°: {dummy_film_params[3][0].shape[1]}") 

    model = RestormerVolterra(in_channels=in_channels, out_channels=out_channels, dim=base_dim)
    print(f"3. RestormerVolterra λ¨λΈ μ΄κΈ°ν™” μ™„λ£. (Base Dim: {base_dim})")
    
    # 4. μμ „ν (Forward Pass) μ‹¤ν–‰
    try:
        output = model(dummy_image, dummy_film_params)
        
        # 5. κ²°κ³Ό ν™•μΈ
        print("\n--- μμ „ν κ²°κ³Ό ---")
        print(f"4. μµμΆ… μ¶λ ¥ μ΄λ―Έμ§€ ν•νƒ (y_hat): {output.shape}")
        
        assert output.shape == dummy_image.shape, "μ…λ ¥κ³Ό μµμΆ… μ¶λ ¥μ ν•νƒκ°€ μΌμΉν•μ§€ μ•μµλ‹λ‹¤! (ν•΄μƒλ„ μ¤λ¥ λ°μƒ)"
        print("5. μ…λ ¥κ³Ό μ¶λ ¥ ν•νƒ μΌμΉ ν™•μΈ: μ„±κ³µ")

        # FiLMμ΄ μ‹¤μ λ΅ μ μ©λμ—λ”μ§€ κ°„μ ‘ ν™•μΈ (λ¨λ“  FiLMμ„ μ¤‘λ¦½μΌλ΅ μ„¤μ •ν•κ³  λΉ„κµ)
        # Note: neutral_film_paramsλ¥Ό λ‹¤μ‹ μƒμ„±ν•  λ•, gamma/betaλ” 1/0μΌλ΅ κ³ μ •ν•΄μ•Ό ν•¨
        neutral_film_params = [(torch.ones_like(g), torch.zeros_like(b)) for g, b in dummy_film_params]
        output_neutral = model(dummy_image, neutral_film_params)
        
        diff = torch.abs(output - output_neutral).sum()
        print(f"6. FiLM λ³€μ΅° μ „/ν›„ μ¶λ ¥ μ°¨μ΄ (L1 Sum): {diff.item():.4f}")
        
        # FiLM νλΌλ―Έν„°μ— λ³€ν™”λ¥Ό μ£Όμ—μΌλ―€λ΅, μ°¨μ΄κ°€ 0λ³΄λ‹¤ μ»¤μ•Ό ν•©λ‹λ‹¤.
        if diff.item() > 0.0: 
            print("   -> FiLM μ μ–΄ μ‹ νΈκ°€ μ„±κ³µμ μΌλ΅ VETNet Backboneμ— μ μ©λμ—μµλ‹λ‹¤. (μ •μƒ μ‘λ™)")
        else:
             print("   -> κ²½κ³ : FiLM λ³€μ΅°κ°€ μ μ©λμ—μΌλ‚ μ¶λ ¥ μ°¨μ΄κ°€ λ°μƒν•μ§€ μ•μ•μµλ‹λ‹¤. (μ¤ν…μ λ¬Έμ μΌ κ°€λ¥μ„± λ†’μ)")
            
    except Exception as e:
        print(f"\n--- μμ „ν μ¤‘ μ¤λ¥ λ°μƒ ---")
        print(f"μ¤λ¥: {e}")
        
    print("\n--- 3λ‹¨κ³„: vetnet_backbone.py μ½”λ“ κ²€μ¦ μ™„λ£ ---")